{"initialization_time": 50.56857776641846, "generate_time": 546.6239945888519, "model_name": "google/gemma-3-4b-it", "tensor_parallel_size": 2, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 82.6790771484375, "generate_time": 703.2215797901154, "model_name": "google/gemma-3-12b-it", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 192.9695587158203, "generate_time": 883.1137204170227, "model_name": "google/gemma-3-27b-it", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 56.764267683029175, "generate_time": 161.72175312042236, "model_name": "google/gemma-2-9b-it", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 169.2115547657013, "generate_time": 219.800297498703, "model_name": "google/gemma-2-27b-it", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 57.009132623672485, "generate_time": 170.04679536819458, "model_name": "CohereLabs/aya-23-8B", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 226.81000137329102, "generate_time": 426.5041491985321, "model_name": "CohereLabs/aya-expanse-32b", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 46.502933979034424, "generate_time": 207.30133152008057, "model_name": "CohereLabs/aya-expanse-8b", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 260.95377135276794, "generate_time": 3704.4996848106384, "model_name": "RedHatAI/DeepSeek-R1-Distill-Llama-70B-quantized.w8a8", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 4096, "max_model_len": 4096}
{"initialization_time": 60.14443612098694, "generate_time": 508.1381494998932, "model_name": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 4096, "max_model_len": 4096}
{"initialization_time": 89.68710374832153, "generate_time": 662.7278609275818, "model_name": "RedHatAI/DeepSeek-R1-Distill-Qwen-32B-quantized.w8a8", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 4096, "max_model_len": 4096}
{"initialization_time": 52.10408067703247, "generate_time": 141.37630033493042, "model_name": "ibm-granite/granite-3.1-8b-instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 22.49685311317444, "generate_time": 41.18292236328125, "model_name": "meta-llama/Llama-3.2-1B-Instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 30.264750957489014, "generate_time": 105.06903767585754, "model_name": "meta-llama/Llama-3.2-3B-Instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 267.80977153778076, "generate_time": 677.0939161777496, "model_name": "RedHatAI/Llama-3.3-70B-Instruct-quantized.w8a8", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 343.86855816841125, "generate_time": 174.94914317131042, "model_name": "mistralai/Mistral-Small-24B-Instruct-2501", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 69.11136794090271, "generate_time": 398.9820783138275, "model_name": "allenai/OLMo-2-1124-13B-Instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 47.91938257217407, "generate_time": 209.12674069404602, "model_name": "allenai/OLMo-2-1124-7B-Instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 72.65187692642212, "generate_time": 280.77390718460083, "model_name": "microsoft/phi-4", "tensor_parallel_size": 2, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 30.261808395385742, "generate_time": 104.99057674407959, "model_name": "microsoft/Phi-4-mini-instruct", "tensor_parallel_size": 2, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 25.51340961456299, "generate_time": 55.990625858306885, "model_name": "Qwen/Qwen2.5-1.5B-Instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 32.06616973876953, "generate_time": 81.58418917655945, "model_name": "Qwen/Qwen2.5-3B-Instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 41.310808181762695, "generate_time": 105.38025307655334, "model_name": "Qwen/Qwen2.5-7B-Instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 83.32754826545715, "generate_time": 145.29813647270203, "model_name": "Qwen/Qwen2.5-14B-Instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 283.4204409122467, "generate_time": 2429.5704820156097, "model_name": "RedHatAI/Qwen2-72B-Instruct-quantized.w8a8", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 57.5556526184082, "generate_time": 877.7388882637024, "model_name": "Qwen/QwQ-32B-AWQ", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 4096, "max_model_len": 4096}
{"initialization_time": 257.2301335334778, "generate_time": 557.0107128620148, "model_name": "RedHatAI/Meta-Llama-3.1-70B-Instruct-quantized.w8a8", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 217.25923871994019, "generate_time": 310.35808634757996, "model_name": "Qwen/Qwen2.5-32B-Instruct", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}
{"initialization_time": 293.69259428977966, "generate_time": 2035.7261776924133, "model_name": "Qwen/Qwen2.5-72B-Instruct-GPTQ-Int8", "tensor_parallel_size": 4, "pipeline_parallel_size": 1, "max_tokens": 1024, "max_model_len": 2048}